{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bb5238-d3d0-47b9-8d28-b6e416dcc68e",
   "metadata": {},
   "source": [
    "# Тест пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc4f1b1e-260d-438a-9c70-968807ac62f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b4874-848f-4947-a61d-b1ae2efc5171",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43569028-fb9d-4e99-8c45-a660024ed525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    gpu_available = True\n",
    "else:\n",
    "    gpu_available = False\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset1 = datasets.MNIST('/homes/flomakin/gun_crypto_system/data',\n",
    "                train=True, download=True,\n",
    "                transform=transform)\n",
    "\n",
    "dataset2 = datasets.MNIST('/homes/flomakin/gun_crypto_system/data',\n",
    "                train=False, download=True,\n",
    "                transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4db8d98-c552-455e-ae4b-a0b6b9b1de6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    i+=1\n",
    "    if i == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38009ad2-2e4a-442d-b003-5658e9dea7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f35a5e8d810>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.min(), data.max())\n",
    "image = data.numpy()\n",
    "plt.imshow(np.squeeze(image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8685573-bbe2-4f7b-bd6c-b5e673848d76",
   "metadata": {},
   "source": [
    "## Модель 1 - Энкодер Декодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1bc57e-fc90-4746-a2a9-959c41c2fb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=2, padding=1)\n",
    "conv3 = nn.Conv2d(96, 288, kernel_size=3, stride=2, padding=1)\n",
    "conv4 = nn.Conv2d(288, 784, kernel_size=5, stride=2, padding=1)\n",
    "deconv4 = nn.ConvTranspose2d(784, 288, kernel_size=5, stride=2, padding=1, output_padding=1)\n",
    "deconv3 = nn.ConvTranspose2d(288, 96, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "deconv2 = nn.ConvTranspose2d(96, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "deconv1 = nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c39a0fb5-935a-4c5e-9400-04d50c134ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = torch.randn(5, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0833e0d-687a-4cf5-948c-c2c07c9bb20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = torch.randn(5, 1, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "32708c0d-ccbf-42db-a3da-8df92611c3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1, 128])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "70c3c753-650c-4cd6-b4e6-b7ac7f67695f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32, 14, 14])\n",
      "torch.Size([5, 96, 7, 7])\n",
      "torch.Size([5, 288, 4, 4])\n",
      "torch.Size([5, 784, 1, 1])\n",
      "torch.Size([5, 288, 4, 4])\n",
      "torch.Size([5, 96, 7, 7])\n",
      "torch.Size([5, 32, 14, 14])\n",
      "torch.Size([5, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a=conv1(image)\n",
    "print(a.shape)\n",
    "b=conv2(a)\n",
    "print(b.shape)\n",
    "c=conv3(b)\n",
    "print(c.shape)\n",
    "d = conv4(c)\n",
    "print(d.shape)\n",
    "e = deconv4(d)\n",
    "print(e.shape)\n",
    "f = deconv3(e)\n",
    "print(f.shape)\n",
    "g = deconv2(f)\n",
    "print(g.shape)\n",
    "h = deconv1(g)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1cd65f5f-76c0-4d5f-b54b-188b7deee9db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 784])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.view(5, 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96133fa-ac1b-4183-ae3a-174f948f0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([x.view(1, -1), k], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0ee1d7ee-0585-4925-a311-6467c69b396c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1, 784])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dod = d.view(d.shape[0], 1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe78f509-c13f-49c3-b6ce-418eaf6cb74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Вход [1, 28, 28]\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(96, 288, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(288, 784, kernel_size=5, stride=2, padding=1)\n",
    "        # Выход [784, 1, 1]\n",
    "        \n",
    "        self.fc1 = nn.Linear(784 + 128, 784)\n",
    "        self.fc2 = nn.Linear(784, 784)\n",
    "        self.fc3 = nn.Linear(784, 784)\n",
    "        \n",
    "        # PReLU activation\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x, k):\n",
    "        # Проход через сверточные слои\n",
    "        x = self.prelu(self.conv1(x))\n",
    "        x = self.prelu(self.conv2(x))\n",
    "        x = self.prelu(self.conv3(x))\n",
    "        x = self.prelu(self.conv4(x))\n",
    "        \n",
    "        # Примешиваем ключ\n",
    "        x = torch.cat([x.view(x.shape[0], 1, 784), k], dim=1)\n",
    "        \n",
    "        x = self.prelu(self.fc1(x))\n",
    "        x = self.prelu(self.fc2(x))\n",
    "        x = nn.Tanh()(self.fc3(x))  # Note: Applying Tanh as a separate layer\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class DecoderBOB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderBOB, self).__init__()\n",
    "\n",
    "        self.fc4 = nn.Linear(784 + 128, 784)\n",
    "        self.fc5 = nn.Linear(784, 784)\n",
    "        self.fc6 = nn.Linear(784, 784)\n",
    "\n",
    "        self.deconv4 = nn.ConvTranspose2d(784, 288, kernel_size=5, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(288, 96, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv2 = nn.ConvTranspose2d(96, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x, k):\n",
    "        x = self.prelu(self.fc4(torch.cat([x, k], dim=1)))\n",
    "        x = self.prelu(self.fc5(x))\n",
    "        x = self.prelu(self.fc6(x))\n",
    "\n",
    "        x = x.view(x.shape[0], 784, 1, 1)\n",
    "\n",
    "        x = self.prelu(self.deconv4(x))\n",
    "        x = self.prelu(self.deconv3(x))\n",
    "        x = self.prelu(self.deconv2(x))\n",
    "        x = nn.Tanh()(self.deconv1(x)) \n",
    "\n",
    "        return x\n",
    "\n",
    "class DecoderEVA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderEVA, self).__init__()\n",
    "\n",
    "        self.fc4 = nn.Linear(784, 784)\n",
    "        self.fc5 = nn.Linear(784, 784)\n",
    "        self.fc6 = nn.Linear(784, 784)\n",
    "\n",
    "        self.deconv4 = nn.ConvTranspose2d(784, 288, kernel_size=5, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(288, 96, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv2 = nn.ConvTranspose2d(96, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prelu(self.fc4(x))\n",
    "        x = self.prelu(self.fc5(x))\n",
    "        x = self.prelu(self.fc6(x))\n",
    "\n",
    "        x = x.view(784, 1, 1)\n",
    "\n",
    "        x = self.prelu(self.deconv4(x))\n",
    "        x = self.prelu(self.deconv3(x))\n",
    "        x = self.prelu(self.deconv2(x))\n",
    "        x = nn.Tanh()(self.deconv1(x))  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3b0de-d73b-4aeb-a435-4fa07307a26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccb2c5f-546f-4c07-9672-3e8d9defd4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en = Encoder()\n",
    "de = Decoder_EVA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ea8659d-72f4-41db-a360-4db1436e1b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.randn(5 ,1, 28, 28)\n",
    "scaled_image = F.tanh(image)\n",
    "k = torch.randn(1, 128)\n",
    "encoded_output = en(image, k)\n",
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ecf1b-7243-47da-b404-936c2f1fc44c",
   "metadata": {},
   "source": [
    "## ЭКСП"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c3fcef3-42e0-4a24-9799-c15ede970708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_steps = 1000\n",
    "learning_rate = 10e-3\n",
    "clip_value = 1\n",
    "def generate_key(size: int = 128, gpu_available: bool = True):\n",
    "    if gpu_available:\n",
    "        return torch.randn(1, size).cuda()\n",
    "    else:\n",
    "        return torch.randn(1, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c239999-814a-4fab-810a-9922ff77f100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1228it [00:45, 26.85it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alice = Encoder()\n",
    "bob = DecoderBOB()\n",
    "eve = DecoderEVA()\n",
    "\n",
    "alice.train()\n",
    "bob.train()\n",
    "eve.train()\n",
    "\n",
    "if gpu_available:\n",
    "    alice.cuda()\n",
    "    bob.cuda()\n",
    "    eve.cuda()\n",
    "\n",
    "aggregated_losses = {\n",
    "        \"alice_bob_training_loss\": [],\n",
    "        \"bob_reconstruction_training_errors\": [],\n",
    "        \"eve_reconstruction_training_errors\": [],\n",
    "        \"step\": []\n",
    "}\n",
    "\n",
    "optimizer_alice = Adam(params=alice.parameters(), lr=learning_rate)\n",
    "optimizer_bob = Adam(params=bob.parameters(), lr=learning_rate)\n",
    "optimizer_eve = Adam(params=eve.parameters(), lr=learning_rate)\n",
    "\n",
    "# define losses \n",
    "bob_reconstruction_error = nn.L1Loss()\n",
    "eve_reconstruction_error = nn.L1Loss()\n",
    "\n",
    "for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "    data = data[0].to('cuda')\n",
    "    # Training alternates between Alice/Bob and Eve\n",
    "    for network, num_minibatches in {\"alice_bob\": 1, \"eve\": 2}.items():\n",
    "        \"\"\" \n",
    "        Alice/Bob training for one minibatch, and then Eve training for two minibatches this ratio \n",
    "        in order to give a slight computational edge to the adversary Eve without training it so much\n",
    "        that it becomes excessively specific to the exact current parameters of Alice and Bob\n",
    "        \"\"\"\n",
    "        for _ in range(num_minibatches):\n",
    "\n",
    "            k = generate_key(size=128, gpu_available=gpu_available)\n",
    "\n",
    "            # forward pass through alice and eve networks\n",
    "\n",
    "            ciphertext = alice.forward(data, k)\n",
    "\n",
    "            eve_p = eve.forward(ciphertext)\n",
    "\n",
    "            if network == \"alice_bob\":\n",
    "\n",
    "                # forward pass through bob network\n",
    "                bob_p = bob.forward(ciphertext, k)\n",
    "\n",
    "                # calculate errors\n",
    "                error_bob = bob_reconstruction_error(input=bob_p, target=data)\n",
    "                error_eve = eve_reconstruction_error(input=eve_p, target=data)\n",
    "                alice_bob_loss =  error_bob + F.relu(1 - error_eve)\n",
    "\n",
    "                # Zero gradients, perform a backward pass, clip gradients, and update the weights.\n",
    "                optimizer_alice.zero_grad()\n",
    "                optimizer_bob.zero_grad()\n",
    "                alice_bob_loss.backward()\n",
    "                nn.utils.clip_grad_value_(alice.parameters(), clip_value)\n",
    "                nn.utils.clip_grad_value_(bob.parameters(), clip_value)\n",
    "                optimizer_alice.step()\n",
    "                optimizer_bob.step()\n",
    "\n",
    "            elif network == \"eve\":\n",
    "\n",
    "                # calculate error\n",
    "                error_eve = eve_reconstruction_error(input=eve_p, target=data)\n",
    "\n",
    "                # Zero gradients, perform a backward pass, and update the weights\n",
    "                optimizer_eve.zero_grad()\n",
    "                error_eve.backward()\n",
    "                nn.utils.clip_grad_value_(eve.parameters(), clip_value)\n",
    "                optimizer_eve.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df6256-f111-4615-b07b-7bd8e1b6a23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
